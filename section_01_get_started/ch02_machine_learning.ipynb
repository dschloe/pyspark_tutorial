{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c137ea-1db7-4dac-9d99-641131de42bd",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3af985e-7947-4c62-94dd-7472905c84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f8308432b20>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"MLSampleTutorial\").getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed7b10a-1e29-4298-a286-f84c684b12e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2014|   12|  8|     658|       -7|     935|       -5|     VX| N846VA|  1780|   SEA| LAX|     132|     954|   6|    58|\n",
      "|2014|    1| 22|    1040|        5|    1505|        5|     AS| N559AS|   851|   SEA| HNL|     360|    2677|  10|    40|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights = spark.read.option('header', 'true').csv(\"data/flight_small.csv\")\n",
    "flights.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea236039-e185-4b06-a63a-45dfc38bcf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "|tailnum|year|                type|    manufacturer|   model|engines|seats|speed|   engine|\n",
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "| N102UW|1998|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "| N103US|1999|Fixed wing multi ...|AIRBUS INDUSTRIE|A320-214|      2|  182|   NA|Turbo-fan|\n",
      "+-------+----+--------------------+----------------+--------+-------+-----+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "planes = spark.read.option('header', 'true').csv(\"data/planes.csv\")\n",
    "planes.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f8cc0-a08d-4f96-b96c-bd82897c9e71",
   "metadata": {},
   "source": [
    "# Join the DataFrames\n",
    "- 두개의 테이블을 Join 하는 코드를 작성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7371de-cbfd-4b89-a947-014ae21fff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename year column\n",
    "planes = planes.withColumnRenamed(\"year\", \"plane_year\")\n",
    "\n",
    "# Join the DataFrames\n",
    "model_data = flights.join(planes, on=\"tailnum\", how=\"leftouter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a169e-57b3-4e51-9977-82aa966be4fb",
   "metadata": {},
   "source": [
    "- Convert String to Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38948f41-b52f-42b7-a6a9-b02622d1f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the columns to integers\n",
    "model_data = model_data.withColumn(\"arr_delay\", model_data.arr_delay.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"air_time\", model_data.air_time.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"month\", model_data.month.cast(\"integer\"))\n",
    "model_data = model_data.withColumn(\"plane_year\", model_data.plane_year.cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e71b1b-8608-4722-a719-e36e625babfd",
   "metadata": {},
   "source": [
    "- 새로운 컬럼을 작성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9246621f-b0bc-4b20-99b3-af8b8c78f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column plane_age\n",
    "model_data = model_data.withColumn(\"plane_age\", model_data.year - model_data.plane_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d83433-1567-4a86-83dd-5dfebc4970a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: integer (nullable = true)\n",
      " |-- distance: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- minute: string (nullable = true)\n",
      " |-- plane_year: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- engines: string (nullable = true)\n",
      " |-- seats: string (nullable = true)\n",
      " |-- speed: string (nullable = true)\n",
      " |-- engine: string (nullable = true)\n",
      " |-- is_late: boolean (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- plane_age: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create is_late\n",
    "model_data = model_data.withColumn(\"is_late\", model_data.arr_delay > 0)\n",
    "\n",
    "# Convert to an integer\n",
    "model_data = model_data.withColumn(\"label\", model_data.is_late.cast(\"integer\"))\n",
    "\n",
    "# Remove missing values\n",
    "model_data = model_data.filter(\"arr_delay is not NULL and dep_delay is not NULL and air_time is not NULL and plane_year is not NULL\")\n",
    "model_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bab4ab-d871-4846-b651-bc14cd08f1a9",
   "metadata": {},
   "source": [
    "- String 문자열을 변환한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4071758-b307-4549-bf22-eb781ffa6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StringIndexer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "carr_indexer = StringIndexer(inputCol=\"carrier\", outputCol=\"carrier_index\")\n",
    "\n",
    "# Create a OneHotEncoder\n",
    "carr_encoder = OneHotEncoder(inputCol=\"carrier_index\", outputCol=\"carrier_fact\")\n",
    "\n",
    "# Create a StringIndexer\n",
    "dest_indexer = StringIndexer(inputCol=\"dest\", outputCol=\"dest_index\")\n",
    "\n",
    "# Create a OneHotEncoder\n",
    "dest_encoder = OneHotEncoder(inputCol=\"dest_index\", outputCol=\"dest_fact\")\n",
    "\n",
    "# Make a VectorAssembler\n",
    "vec_assembler = VectorAssembler(inputCols=[\"month\", \"air_time\", \"carrier_fact\", \"dest_fact\", \"plane_age\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea82eef-be47-4460-9502-e08463721a56",
   "metadata": {},
   "source": [
    "- Pipeline을 구축한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52cf5025-33fa-4958-a77a-b6208cd139f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Make the pipeline\n",
    "flights_pipe = Pipeline(stages=[dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec4113-e25d-4005-b0c8-b7b8ea2ffc5c",
   "metadata": {},
   "source": [
    "- 구축된 Pipeline을 데이터에 적합시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "075769ee-4718-4089-bbfe-af35059956de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "piped_data = flights_pipe.fit(model_data).transform(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34956944-a44d-44ca-acbd-29ac3c35b6e4",
   "metadata": {},
   "source": [
    "- 데이터를 분리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62e7b881-1063-4c20-ab7c-3f86ddee3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "training, test = piped_data.randomSplit([.6, .4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8001a-00b0-4422-ab31-2c2633c48bc8",
   "metadata": {},
   "source": [
    "- 모델을 생성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c4ddfe0-605c-4226-9b1d-39e954171520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create a LogisticRegression Estimator\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5e3c8-f976-445e-a238-93ba371401ed",
   "metadata": {},
   "source": [
    "- 모형성능의 Evaluator를 생성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8aa8a4d5-37bf-4e95-880c-5837533244f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the evaluation submodule\n",
    "import pyspark.ml.evaluation as evals\n",
    "\n",
    "# Create a BinaryClassificationEvaluator\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521b5ac-2b6c-4e49-b74b-2c9c45226c98",
   "metadata": {},
   "source": [
    "- 그리드 서치를 위한 매개변수를 설정 및 CrossValidator를 설정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20af4c52-d608-4a95-9319-98a8a498682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tuning submodule\n",
    "import pyspark.ml.tuning as tune\n",
    "import numpy as np\n",
    "\n",
    "# Create the parameter grid\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# Add the hyperparameter\n",
    "grid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(lr.elasticNetParam, [0, 1])\n",
    "\n",
    "# Build the grid\n",
    "grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67a013d9-1fdb-4ed2-898b-fb0078f5ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CrossValidator\n",
    "cv = tune.CrossValidator(estimator=lr,\n",
    "                         estimatorParamMaps=grid,\n",
    "                         evaluator=evaluator\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845764b-3046-4849-b007-df7eed9e6e33",
   "metadata": {},
   "source": [
    "- 모형을 적합시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e009f3fd-8e12-4593-9b02-08e18ecd4b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel: uid=LogisticRegression_8e25b909fd01, numClasses=2, numFeatures=81\n"
     ]
    }
   ],
   "source": [
    "# Call lr.fit()\n",
    "best_lr = lr.fit(training)\n",
    "\n",
    "# Print best_lr\n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06151193-0fff-4bdb-b0bd-72b93e230cb0",
   "metadata": {},
   "source": [
    "- 모형을 평가한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f59bc4ba-b6a3-4998-a16a-ebd55b2dec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7067877467577143\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the test set\n",
    "test_results = best_lr.transform(test)\n",
    "\n",
    "# Evaluate the predictions (=AUC)\n",
    "print(evaluator.evaluate(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da483d85-d02d-4874-a0ac-7d5312e4cb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
